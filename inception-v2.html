<html>
<head><title>Inception v2</title></head>
<body>
<h1>What is Inception-v2?</h1>
  
  <h2>It's Inception plus Batch Normalization and some 5x5 factoring</h2>
  
  <p>In <a href="https://arxiv.org/abs/1602.07261">Inception-v4</a>, Szegedy et al. describe Inception-v2:</p>
  <blockquote>"Later the Inception architecture was refined in various ways, first by the introduction of batch normalization
  (Inception-v2) by Ioffe et al."</blockquote>

  <p>That paper by <a href="">Ioffe et al.</a> describes their model like this:</p>

<blockquote>"The main difference to [Inception-v1] is that the 5 × 5
convolutional layers are replaced by two consecutive layers
  of 3 × 3 convolutions with up to 128 filters."</blockquote>

  <h2>It's an intermediate variant of Inception before -v3, and different than batch-normalized Inception</h2>
  
  <p><a href="https://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a> has a section (Section 6) titled "Inception-v2". It 
describes a network with many more changes than the Batch Normalization paper listed compared to Inception-v1.</p>
  
  <p>It
also includes a table that has separate entries for "BN-GoogLeNet", "BN-Inception", and "Inception-v2". (This introduces an
  new question: Is GoogLeNet different than Inception?)</p>

</body>
</html>
