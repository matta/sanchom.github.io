<html>
  <head>
    <title>Inception v2</title>
  <style>
    body {
      margin-right: 20%;
      margin-left: 20%;
    }
    .centering {
      display: flex;
      justify-content: center;
      padding-left: 30%;
      padding-right: 30%;
    }
    img {
      height: 100%;
      width: auto;
    }
    </style>
  </head>
<body>
<h1>What is Inception-v2?</h1>
  
  <h2>It's Inception plus Batch Normalization and some 5x5 factoring</h2>
  
  <p>In <a href="https://arxiv.org/abs/1602.07261">Inception-v4</a>, Szegedy et al. describe Inception-v2:</p>
  <blockquote>"Later the Inception architecture was refined in various ways, first by the introduction of batch normalization
  (Inception-v2) by Ioffe et al."</blockquote>

  <p>That paper by <a href="">Ioffe et al.</a> describes their model like this:</p>

<blockquote>"The main difference to [Inception-v1] is that the 5 × 5
convolutional layers are replaced by two consecutive layers
  of 3 × 3 convolutions with up to 128 filters."</blockquote>

  <h2>It's an intermediate variant of Inception before -v3, and different than batch-normalized Inception</h2>
  
  <p><a href="https://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a> has a section (Section 6) titled "Inception-v2". It 
describes a network with many more changes than the Batch Normalization paper listed compared to Inception-v1:</p>
  
  <blockquote>"Here we are connecting the dots from above and propose
a new architecture with improved performance on the
ILSVRC 2012 classification benchmark. The layout of our
network is given in table 1. Note that we have factorized
the traditional 7 × 7 convolution into three 3 × 3 convolutions
based on the same ideas as described in section 3.1.
For the Inception part of the network, we have 3 traditional
inception modules at the 35×35 with 288 filters each. This
is reduced to a 17 × 17 grid with 768 filters using the grid
reduction technique described in section 5. This is is followed
by 5 instances of the factorized inception modules as
depicted in figure 5. This is reduced to a 8 × 8 × 1280 grid
with the grid reduction technique depicted in figure 10. At
the coarsest 8 × 8 level, we have two Inception modules as
depicted in figure 6, with a concatenated output filter bank
size of 2048 for each tile. The detailed structure of the network,
including the sizes of filter banks inside the Inception
modules, is given in the supplementary material, given in
    the <b>model.txt</b> that is in the tar-file of this submission."</blockquote>
  
  <div class="centering">
  <img src="assets/possibly-inception-v2.png" />
  </div>
  
  <p>I can't find this model.txt file anywhere on the internet.</p>
  <p>"Rethinking Inception"
    also includes a table that has separate entries for:</p>
  <ul>
    <li>BN-GoogLeNet</li>
    <li>BN-Inception</li>
    <li>Inception-v2</li>
  </ul>

</body>
</html>
